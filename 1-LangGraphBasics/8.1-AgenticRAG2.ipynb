{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19ab913a",
   "metadata": {},
   "source": [
    "**Agentic RAG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da2985b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.tools import Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64c96f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0a7a99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_retriever_tool_for_webdoc(urls, name, desc):\n",
    "    \"\"\"Create a retrieval tool from a web based docs file.\"\"\"\n",
    "    \n",
    "    docs=[WebBaseLoader(url).load() for url in urls]\n",
    "    docs_list = [item for sublist in docs for item in sublist]\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=100\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(docs_list)\n",
    "    vs = FAISS.from_documents(chunks, OpenAIEmbeddings())\n",
    "    retriever = vs.as_retriever()\n",
    "\n",
    "    # function the tool will run\n",
    "    def dynamic_retriever(query: str) -> str:\n",
    "        results = retriever.invoke(query)\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in results)\n",
    "\n",
    "    # create a LangChain tool manually\n",
    "    return Tool(\n",
    "        name=name,\n",
    "        description=desc,\n",
    "        func=dynamic_retriever\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8889db67",
   "metadata": {},
   "source": [
    "**LangGraph blogs in First Vector Database - used as `Retriever_tool_1`** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "706e2335",
   "metadata": {},
   "outputs": [],
   "source": [
    "LangGraph_urls=[\n",
    "    \"https://langchain-ai.github.io/langgraph/tutorials/introduction/\",\n",
    "    \"https://langchain-ai.github.io/langgraph/tutorials/workflows/\",\n",
    "    \"https://langchain-ai.github.io/langgraph/how-tos/map-reduce/\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceea5645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool(name='LangGraph_Documents', description='Search LangGraph Documents for information regarding LangGraph.', func=<function make_retriever_tool_for_webdoc.<locals>.dynamic_retriever at 0x00000234114200E0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Retriever_tool_1=make_retriever_tool_for_webdoc(\n",
    "    urls=LangGraph_urls,\n",
    "    name=\"LangGraph_Documents\",\n",
    "    desc=\"Search LangGraph Documents for information regarding LangGraph.\"\n",
    ")\n",
    "Retriever_tool_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ac6e08",
   "metadata": {},
   "source": [
    "**LangChain blogs in Second Vector Database - used as `Retriever_tool_2`** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c2ed2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "LangChain_urls=[\n",
    "    \"https://python.langchain.com/docs/tutorials/\",\n",
    "    \"https://python.langchain.com/docs/tutorials/chatbot/\",\n",
    "    \"https://python.langchain.com/docs/tutorials/qa_chat_history/\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af4f9172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool(name='LangChain_Documents', description='Search LangChain Documents for information regarding LangChain.', func=<function make_retriever_tool_for_webdoc.<locals>.dynamic_retriever at 0x000002341197FEC0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Retriever_tool_2=make_retriever_tool_for_webdoc(\n",
    "    urls=LangChain_urls,\n",
    "    name=\"LangChain_Documents\",\n",
    "    desc=\"Search LangChain Documents for information regarding LangChain.\"\n",
    ")\n",
    "Retriever_tool_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d119de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [Retriever_tool_1,Retriever_tool_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760a65ca",
   "metadata": {},
   "source": [
    "**LangGraph Workflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "127c309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Sequence,Literal\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_classic import hub\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # The add_messages reducer defines how an update should be processed\n",
    "    # Default is to replace. add_messages says \"append\"\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5176f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node\n",
    "def agent(state):\n",
    "    \"\"\"\n",
    "    Invokes the agent model to generate a response based on the current state. Given\n",
    "    the question, it will decide to retrieve using the retriever tool, or simply end.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with the agent response appended to messages\n",
    "    \"\"\"\n",
    "    print(\"---CALL AGENT---\")\n",
    "    messages = state[\"messages\"]\n",
    "    model = ChatGroq(model=\"qwen/qwen3-32b\")\n",
    "    model = model.bind_tools(tools)\n",
    "    response = model.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed80d86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node\n",
    "def grade_documents(state) -> Literal[\"generate\", \"rewrite\"]:\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        str: A decision for whether the documents are relevant or not\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK RELEVANCE---\")\n",
    "\n",
    "    # Data model\n",
    "    class grade(BaseModel):\n",
    "        \"\"\"Binary score for relevance check.\"\"\"\n",
    "        binary_score: str = Field(description=\"Relevance score 'yes' or 'no'\")\n",
    "\n",
    "    # LLM\n",
    "    model = ChatGroq(model=\"qwen/qwen3-32b\")\n",
    "\n",
    "    # LLM with tool and validation\n",
    "    llm_with_tool = model.with_structured_output(grade)\n",
    "\n",
    "    # Prompt\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "        Here is the retrieved document: \\n\\n {context} \\n\\n\n",
    "        Here is the user question: {question} \\n\n",
    "        If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\",\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "\n",
    "    # Chain\n",
    "    chain = prompt | llm_with_tool\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    question = messages[0].content\n",
    "    docs = last_message.content\n",
    "\n",
    "    scored_result = chain.invoke({\"question\": question, \"context\": docs})\n",
    "\n",
    "    score = scored_result.binary_score\n",
    "\n",
    "    if score == \"yes\":\n",
    "        print(\"---DECISION: DOCS RELEVANT---\")\n",
    "        return \"generate\"\n",
    "\n",
    "    else:\n",
    "        print(\"---DECISION: DOCS NOT RELEVANT---\")\n",
    "        print(score)\n",
    "        return \"rewrite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "884aa9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "         dict: The updated message\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    docs = last_message.content\n",
    "\n",
    "    # Prompt\n",
    "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "    # LLM\n",
    "    llm = ChatGroq(model=\"qwen/qwen3-32b\")\n",
    "\n",
    "    # Post-processing\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    # Chain\n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    # Run\n",
    "    response = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa2a563b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node\n",
    "def rewrite(state):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with re-phrased question\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "\n",
    "    msg = [\n",
    "        HumanMessage(\n",
    "            content=f\"\"\" \\n \n",
    "    Look at the input and try to reason about the underlying semantic intent / meaning. \\n \n",
    "    Here is the initial question:\n",
    "    \\n ------- \\n\n",
    "    {question} \n",
    "    \\n ------- \\n\n",
    "    Formulate an improved question: \"\"\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Grader\n",
    "    model = ChatGroq(model=\"qwen/qwen3-32b\")\n",
    "    response = model.invoke(msg)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26bbd7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Producing the StateGraph\n",
    "from langgraph.graph import START, END, StateGraph \n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the nodes we will cycle between\n",
    "workflow.add_node(\"agent\", agent)  # agent\n",
    "retrieve = ToolNode([Retriever_tool_1, Retriever_tool_2])\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieval\n",
    "workflow.add_node(\"rewrite\", rewrite)  # Re-writing the question\n",
    "workflow.add_node(\n",
    "    \"generate\", generate\n",
    ")  # Generating a response after we know the documents are relevant\n",
    "\n",
    "# Edges\n",
    "# Call agent node to decide to retrieve or not\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# Decide whether to retrieve\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    # Assess agent decision\n",
    "    tools_condition,\n",
    "    {\n",
    "        # Translate the condition outputs to nodes in our graph\n",
    "        \"tools\": \"retrieve\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Edges taken after the `action` node is called\n",
    "# After the grade_documents is called, it returns either generate or rewrite \n",
    "# That is why it we dont add it in the same workflow of grade_documents\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve\",\n",
    "    # Assess agent decision\n",
    "    grade_documents,\n",
    ")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "workflow.add_edge(\"rewrite\", \"agent\")\n",
    "\n",
    "# Compile\n",
    "graph = workflow.compile()\n",
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "661decb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CALL AGENT---\n",
      "---CHECK RELEVANCE---\n",
      "---DECISION: DOCS NOT RELEVANT---\n",
      "no\n",
      "---TRANSFORM QUERY---\n",
      "---CALL AGENT---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is LangGraph?', additional_kwargs={}, response_metadata={}, id='e45c01f2-154b-4ca6-af27-42646cc64d06'),\n",
       "  AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, the user is asking, \"What is LangGraph?\" I need to figure out which tool to use here. The available tools are LangGraph_Documents and LangChain_Documents. Since the question is about LangGraph itself, the most straightforward approach is to use the LangGraph_Documents function. The parameters require a __arg1, which I assume is the search query. So I\\'ll input \"What is LangGraph?\" into that. I don\\'t need to use the LangChain one because the question isn\\'t about LangChain. Just make sure the JSON is correctly formatted with the function name and arguments. Let me double-check the syntax to avoid any errors.\\n', 'tool_calls': [{'id': '9bgmjyajy', 'function': {'arguments': '{\"__arg1\":\"What is LangGraph?\"}', 'name': 'LangGraph_Documents'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 171, 'prompt_tokens': 241, 'total_tokens': 412, 'completion_time': 0.367254772, 'prompt_time': 0.010459778, 'queue_time': 0.148098467, 'total_time': 0.37771455, 'completion_tokens_details': {'reasoning_tokens': 138}}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_0bbb77f8a9', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--318e20fb-70d7-4611-be10-a6f3a0bca5ad-0', tool_calls=[{'name': 'LangGraph_Documents', 'args': {'__arg1': 'What is LangGraph?'}, 'id': '9bgmjyajy', 'type': 'tool_call'}], usage_metadata={'input_tokens': 241, 'output_tokens': 171, 'total_tokens': 412, 'output_token_details': {'reasoning': 138}}),\n",
       "  ToolMessage(content='Redirecting...\\n\\n\\n\\n\\n\\n\\nRedirecting...\\n\\nRedirecting...\\n\\n\\n\\n\\n\\n\\nRedirecting...\\n\\nRedirecting...\\n\\n\\n\\n\\n\\n\\nRedirecting...', name='LangGraph_Documents', id='26015a17-3b13-4571-baf4-fced320c1cc0', tool_call_id='9bgmjyajy'),\n",
       "  AIMessage(content='<think>\\nOkay, the user asked, \"What is LangGraph?\" Let me start by understanding what LangGraph is. I know that LangGraph is a framework related to large language models, but I need to be precise.\\n\\nFirst, I should consider the context in which someone would ask this. They might be a developer looking for tools to work with LLMs, or maybe someone new to the field trying to understand the ecosystem. The original question is straightforward, but maybe the user wants more specific information.\\n\\nThe improved question needs to capture the essence of the original but be more targeted. Instead of a general definition, perhaps they want to know its purpose, how it functions, or its use cases. For example, is LangGraph a library for building applications with LLMs, or does it offer something else like a graph-based interface for model training?\\n\\nI should also think about possible ambiguities. \"LangGraph\" could refer to different things if not specified. But given the context of LLMs, it\\'s likely the framework developed by LangChain. So clarifying that it\\'s part of the LangChain ecosystem might be important.\\n\\nAnother angle: the user might be interested in technical aspects like how LangGraph integrates with other tools, its architecture, or specific features such as workflow management or state handling. The improved question should prompt a comprehensive answer that covers these areas without being too vague.\\n\\nI need to ensure the question is clear and direct enough to get a detailed response. Maybe something like, \"What is LangGraph and how is it used in the context of large language model applications?\" That way, it addresses both the definition and the application, guiding the answer to be more informative.\\n</think>\\n\\n**Improved Question:**  \\n\"What is LangGraph, and how does it facilitate the development and deployment of applications using large language models (LLMs)?\"  \\n\\n**Reasoning:**  \\nThe improved question clarifies the semantic intent by explicitly linking LangGraph to its role in LLM application development. It shifts from a generic definition to a focus on functionality and practical use cases, which better addresses the likely underlying interest in understanding its purpose, architecture, or integration with LLM workflows. This also helps avoid ambiguity (e.g., distinguishing it from unrelated tools or frameworks).', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 455, 'prompt_tokens': 54, 'total_tokens': 509, 'completion_time': 1.191808818, 'prompt_time': 0.002172993, 'queue_time': 0.148140969, 'total_time': 1.193981811}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_0bbb77f8a9', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--766f2c0a-594e-4312-808e-381e5dd88b29-0', usage_metadata={'input_tokens': 54, 'output_tokens': 455, 'total_tokens': 509}),\n",
       "  AIMessage(content='It seems I was unable to retrieve specific documentation about LangGraph through the provided tool. However, based on general knowledge:\\n\\n**LangGraph** is a framework designed to simplify the development and deployment of applications using large language models (LLMs). It integrates with **LangChain** to provide tools for managing workflows, handling application state, and orchestrating complex interactions between LLMs and external systems. Key features often include:\\n\\n- **Workflow management**: Define and execute multi-step processes involving LLMs, databases, or APIs.\\n- **State management**: Track and manage application state during multi-turn conversations or long-running tasks.\\n- **Modular components**: Reusable building blocks for common tasks like memory storage, routing, or tool integration.\\n\\nFor detailed information, I recommend consulting the official LangGraph documentation or GitHub repository. Would you like guidance on how to explore these resources further?', additional_kwargs={'reasoning_content': 'Okay, the user asked \"What is LangGraph?\" and I used the LangGraph_Documents tool to search for information. The initial response was just a series of redirecting... messages, which didn\\'t provide any useful content. Then, the assistant suggested an improved question focusing on how LangGraph facilitates LLM application development. Now, the user\\'s latest input is empty, maybe they are waiting for a proper answer.\\n\\nSince the tool didn\\'t return any data, I need to handle this gracefully. I should inform the user that I couldn\\'t retrieve information from the documents and offer an alternative approach. Maybe I can provide a general explanation based on my existing knowledge. Let me check if that\\'s allowed. The user might appreciate knowing that while the tool didn\\'t work, I can still offer a basic overview. I should mention that LangGraph is a framework for building applications with LLMs, focusing on workflow management, state handling, and integration with LangChain. Also, I should suggest they check official resources for detailed info. Need to keep it clear and helpful without overstepping.\\n'}, response_metadata={'token_usage': {'completion_tokens': 399, 'prompt_tokens': 425, 'total_tokens': 824, 'completion_time': 1.602053229, 'prompt_time': 0.022178885, 'queue_time': 0.164893706, 'total_time': 1.624232114, 'completion_tokens_details': {'reasoning_tokens': 219}}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_228bd8fb0d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--6714538c-1da8-4e0a-ac5d-700c98d890f3-0', usage_metadata={'input_tokens': 425, 'output_tokens': 399, 'total_tokens': 824, 'output_token_details': {'reasoning': 219}})]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"messages\":\"What is LangGraph?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "448a376d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CALL AGENT---\n",
      "---CHECK RELEVANCE---\n",
      "---DECISION: DOCS RELEVANT---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is Langchain?', additional_kwargs={}, response_metadata={}, id='da79ff03-d57c-41f0-a293-5820dbc98a33'),\n",
       "  AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, the user is asking, \"What is Langchain?\" I need to figure out which tool to use here. Looking at the available functions, there\\'s one called LangChain_Documents that searches for information about LangChain. The other is for LangGraph. Since the question is about LangChain, I should use the LangChain_Documents function. The parameters require a string argument, which I\\'ll use to query the definition or overview of LangChain. I\\'ll structure the tool call with the appropriate name and arguments.\\n', 'tool_calls': [{'id': 'kn92mr827', 'function': {'arguments': '{\"__arg1\":\"What is LangChain?\"}', 'name': 'LangChain_Documents'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 140, 'prompt_tokens': 241, 'total_tokens': 381, 'completion_time': 0.277450527, 'prompt_time': 0.009797932, 'queue_time': 0.090977419, 'total_time': 0.287248459, 'completion_tokens_details': {'reasoning_tokens': 107}}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--4ee6702a-9932-4477-b9d5-ded70d395390-0', tool_calls=[{'name': 'LangChain_Documents', 'args': {'__arg1': 'What is LangChain?'}, 'id': 'kn92mr827', 'type': 'tool_call'}], usage_metadata={'input_tokens': 241, 'output_tokens': 140, 'total_tokens': 381, 'output_token_details': {'reasoning': 107}}),\n",
       "  ToolMessage(content='Build a RAG agent with LangChain - Docs by LangChainSkip to main contentDocs by LangChain home pageLangChain + LangGraphSearch...⌘KGitHubTry LangSmithTry LangSmithSearch...NavigationLangChainBuild a RAG agent with LangChainLangChainLangGraphDeep AgentsIntegrationsLearnReferenceContributePythonLearnTutorialsLangChainSemantic searchRAG agentSQL agentSupervisor agentLangGraphConceptual overviewsMemoryContextGraph APIFunctional APIAdditional resourcesLangChain AcademyCase studiesOn this pageOverviewConceptsPreviewSetupInstallationLangSmithComponents1. IndexingLoading documentsSplitting documentsStoring documents2. Retrieval and GenerationRAG agentsRAG chainsNext stepsTutorialsLangChainBuild a RAG agent with LangChainCopy pageCopy page\\u200bOverview\\n\\nBuild a RAG agent with LangChain - Docs by LangChainSkip to main contentDocs by LangChain home pageLangChain + LangGraphSearch...⌘KGitHubTry LangSmithTry LangSmithSearch...NavigationLangChainBuild a RAG agent with LangChainLangChainLangGraphDeep AgentsIntegrationsLearnReferenceContributePythonLearnTutorialsLangChainSemantic searchRAG agentSQL agentSupervisor agentLangGraphConceptual overviewsMemoryContextGraph APIFunctional APIAdditional resourcesLangChain AcademyCase studiesOn this pageOverviewConceptsPreviewSetupInstallationLangSmithComponents1. IndexingLoading documentsSplitting documentsStoring documents2. Retrieval and GenerationRAG agentsRAG chainsNext stepsTutorialsLangChainBuild a RAG agent with LangChainCopy pageCopy page\\u200bOverview\\n\\nBuild a RAG agent with LangChain - Docs by LangChainSkip to main contentDocs by LangChain home pageLangChain + LangGraphSearch...⌘KGitHubTry LangSmithTry LangSmithSearch...NavigationLangChainBuild a RAG agent with LangChainLangChainLangGraphDeep AgentsIntegrationsLearnReferenceContributePythonLearnTutorialsLangChainSemantic searchRAG agentSQL agentSupervisor agentLangGraphConceptual overviewsMemoryContextGraph APIFunctional APIAdditional resourcesLangChain AcademyCase studiesOn this pageOverviewConceptsPreviewSetupInstallationLangSmithComponents1. IndexingLoading documentsSplitting documentsStoring documents2. Retrieval and GenerationRAG agentsRAG chainsNext stepsTutorialsLangChainBuild a RAG agent with LangChainCopy pageCopy page\\u200bOverview\\n\\nFor more details, see our Installation guide.\\n\\u200bLangSmith\\nMany of the applications you build with LangChain will contain multiple steps with multiple invocations of LLM calls. As these applications get more complex, it becomes crucial to be able to inspect what exactly is going on inside your chain or agent. The best way to do this is with LangSmith.\\nAfter you sign up at the link above, make sure to set your environment variables to start logging traces:\\nCopyAsk AIexport LANGSMITH_TRACING=\"true\"\\nexport LANGSMITH_API_KEY=\"...\"\\n\\nOr, set them in Python:\\nCopyAsk AIimport getpass\\nimport os\\n\\nos.environ[\"LANGSMITH_TRACING\"] = \"true\"\\nos.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()', name='LangChain_Documents', id='33dc00a8-c295-4656-a969-386f328156f8', tool_call_id='kn92mr827'),\n",
       "  HumanMessage(content='<think>\\nOkay, the user is asking, \"What is Langchain?\" Let me look at the provided context.\\n\\nThe context seems to be from LangChain\\'s documentation, specifically a guide on building a RAG agent. It mentions components like indexing, retrieval, generation, RAG agents, and integration with LangSmith. There\\'s a lot of repetition in the context, maybe from different sections of the docs. \\n\\nLangChain is a framework for building applications with large language models. The key points here are RAG (Retrieval-Augmented Generation) agents, which combine retrieving information from documents and generating responses using LLMs. The context also refers to LangSmith for tracking and debugging complex applications. \\n\\nSo, putting it together: LangChain is a framework that helps in creating apps with LLMs, especially RAG agents, and it integrates tools like LangSmith for monitoring. I need to present this concisely in three sentences. Make sure not to include any technical steps from the context, just the definition and main purpose.\\n</think>\\n\\nLangChain is a framework designed to simplify building applications with large language models (LLMs), particularly focusing on workflows like Retrieval-Augmented Generation (RAG) agents. It provides tools for indexing documents, retrieving information, and integrating LLMs to generate responses. Additionally, it offers LangSmith for tracking and debugging complex chains of LLM interactions.', additional_kwargs={}, response_metadata={}, id='34511f4b-1758-46bc-b550-c83e198a8172')]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"messages\":\"What is Langchain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c03cb88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CALL AGENT---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is Machine learning?', additional_kwargs={}, response_metadata={}, id='93d53464-7838-43b6-b0c0-e153e74b7a08'),\n",
       "  AIMessage(content=\"The functions provided are for searching specific documentation related to LangGraph and LangChain, which are tools within the LangChain ecosystem. Since your question is a general one about the definition of machine learning, these tools are not the best fit for providing an answer. Let me instead provide a straightforward explanation:\\n\\n**Machine learning** is a subset of artificial intelligence (AI) that focuses on building systems that can learn patterns and make decisions from data without being explicitly programmed for specific tasks. It involves algorithms that improve their performance on a task through experience (i.e., by analyzing data). Key types include:\\n- **Supervised learning** (using labeled data to predict outcomes),\\n- **Unsupervised learning** (finding patterns in unlabeled data),\\n- **Reinforcement learning** (learning through trial and error with rewards/penalties).\\n\\nLet me know if you'd like further clarification!\", additional_kwargs={'reasoning_content': 'Okay, the user is asking, \"What is Machine learning?\" Let me think about how to approach this.\\n\\nFirst, I need to check if the provided tools can help. The available functions are LangGraph_Documents and LangChain_Documents. Both are for searching specific documentation related to LangGraph and LangChain, which are probably frameworks or libraries related to machine learning or AI. However, the user\\'s question is a general one about the definition of machine learning. \\n\\nSince the tools are for specific documentation, they might not provide a general explanation. The user isn\\'t asking about LangGraph or LangChain specifically, so using these tools might not be the best approach. If I call either function with the query \"What is Machine learning?\", the results might not be relevant or could be too technical. \\n\\nTherefore, I should conclude that the available tools aren\\'t suitable for answering this general question. It\\'s better to provide a direct, clear explanation of machine learning based on my existing knowledge. I should inform the user that the tools don\\'t cover general ML definitions and then offer the explanation.\\n'}, response_metadata={'token_usage': {'completion_tokens': 401, 'prompt_tokens': 241, 'total_tokens': 642, 'completion_time': 1.221591431, 'prompt_time': 0.010843356, 'queue_time': 0.0911819, 'total_time': 1.232434787, 'completion_tokens_details': {'reasoning_tokens': 220}}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--9cc04dc6-d8a7-4ba9-9458-149647127b44-0', usage_metadata={'input_tokens': 241, 'output_tokens': 401, 'total_tokens': 642, 'output_token_details': {'reasoning': 220}})]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In this example, the LLM did not find the need to check for relevance\n",
    "graph.invoke({\"messages\":\"What is Machine learning?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
